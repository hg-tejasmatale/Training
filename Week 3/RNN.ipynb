{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7671ccb",
   "metadata": {},
   "source": [
    "HOSPITAL PATIENT DETERIORATION PREDICTION\n",
    "Scenario: ICU Patient Health Risk Forecasting\n",
    "A hospital ICU continuously monitors critical patient vitals.\n",
    "The goal is to predict the patientâ€™s risk score for the next 6 hours using the previous 12 hours of multivariate time-series data, so doctors can intervene before a medical emergency occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2482824",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbf02f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2d02b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hour  HR   BP  O2  Resp  Temp  risk_score\n",
      "0     1  82  120  98    16  36.8    0.000000\n",
      "1     2  85  118  97    17  36.9    6.504384\n",
      "2     3  88  115  96    18  37.0   13.580608\n",
      "3     4  92  112  95    19  37.1   21.454831\n",
      "4     5  96  108  94    20  37.2   29.900894\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "lookback = 12\n",
    "horizon = 6\n",
    "\n",
    "df = pd.read_csv('vitals_dataset_48h_with_risk.csv')\n",
    "features = [\"HR\", \"BP\", \"O2\", \"Resp\", \"Temp\"]\n",
    "target = 'risk_score'\n",
    "print(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "689f4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window(df,features,target,lookback=12,horizon=6):\n",
    "    Xv= df[features].values\n",
    "    yv= df[target].values\n",
    "\n",
    "    x_list,y_list = [],[]\n",
    "\n",
    "    for i in range(len(df) - lookback - horizon +1):\n",
    "        x_list.append(Xv[i:i+lookback])\n",
    "        y_list.append(yv[i+lookback:i+lookback+horizon])\n",
    "    return np.array(x_list),np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e68c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_window(df,features,target,lookback,horizon)\n",
    "n = len(X)\n",
    "split = int(0.8*n)\n",
    "\n",
    "X_train, X_val = X[:split], X[split:]\n",
    "y_train, y_val = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88ed8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler()\n",
    "N, T, F = X_train.shape\n",
    "\n",
    "X_train_2d = X_train.reshape(-1, F)\n",
    "X_val_2d   = X_val.reshape(-1, F)\n",
    "\n",
    "x_scaler.fit(X_train_2d)\n",
    "X_train = x_scaler.transform(X_train_2d).reshape(N, T, F)\n",
    "X_val   = x_scaler.transform(X_val_2d).reshape(X_val.shape[0], T, F)\n",
    "\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1)).reshape(y_train.shape)\n",
    "y_val_scaled   = y_scaler.transform(y_val.reshape(-1, 1)).reshape(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82706c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, horizon):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(64, activation=\"tanh\", input_shape=input_shape),\n",
    "        Dropout(0.25),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af9a8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_report(optimizer, label=\"\"):\n",
    "    tf.random.set_seed(1)\n",
    "\n",
    "    model = build_model((lookback, F), horizon)\n",
    "\n",
    "    # Huber loss reduces sensitivity to outliers/spikes\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.Huber(delta=1.0),\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train_scaled,\n",
    "        validation_data=(X_val, y_val_scaled),\n",
    "        epochs=200,\n",
    "        batch_size=8,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    best_epoch = int(np.argmin(history.history[\"val_loss\"]))\n",
    "    best_train_loss = float(history.history[\"loss\"][best_epoch])\n",
    "    best_val_loss   = float(history.history[\"val_loss\"][best_epoch])\n",
    "\n",
    "    if label == \"\":\n",
    "        print(f\"\\nFinal train loss: {best_train_loss}\")\n",
    "        print(f\"Final val loss  : {best_val_loss}\")\n",
    "    else:\n",
    "        print(f\"\\nFinal train loss ({label}): {best_train_loss}\")\n",
    "        print(f\"Final val loss  ({label}): {best_val_loss}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36475b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Training\\.venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final train loss (SGD): 0.0582413524389267\n",
      "Final val loss  (SGD): 0.008881419897079468\n",
      "\n",
      "Final train loss (Adam): 0.38756808638572693\n",
      "Final val loss  (Adam): 0.012296125292778015\n",
      "\n",
      "Last 12 hours risk_score: [25.91 27.54 28.48 29.38 30.77 31.89 32.59 30.1  29.2  26.2  25.97 26.41]\n",
      "Predicted risk next 6 hours (SGD) :  [30.44 31.99 27.89 30.76 31.32 26.78]\n",
      "Predicted risk next 6 hours (Adam):  [31.89 28.34 31.48 28.73 31.08 28.15]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sgd  = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, clipnorm=1.0)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.1, clipnorm=1.0)\n",
    "\n",
    "model_sgd  = train_and_report(sgd,  label=\"SGD\")\n",
    "model_adam = train_and_report(adam, label=\"Adam\")\n",
    "\n",
    "last_12_vitals = df[features].tail(lookback).values\n",
    "last_12_scaled = x_scaler.transform(last_12_vitals).reshape(1, lookback, F)\n",
    "\n",
    "pred_sgd_scaled  = model_sgd.predict(last_12_scaled,  verbose=0)[0] \n",
    "pred_adam_scaled = model_adam.predict(last_12_scaled, verbose=0)[0] \n",
    "\n",
    "# invert scaling to original risk_score scale\n",
    "pred_sgd  = y_scaler.inverse_transform(pred_sgd_scaled.reshape(-1, 1)).reshape(-1)\n",
    "pred_adam = y_scaler.inverse_transform(pred_adam_scaled.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "last_12_risk = df[target].tail(lookback).values\n",
    "\n",
    "print(\"\\nLast 12 hours risk_score:\", np.round(last_12_risk, 2))\n",
    "print(\"Predicted risk next 6 hours (SGD) : \", np.round(pred_sgd, 2))\n",
    "print(\"Predicted risk next 6 hours (Adam): \", np.round(pred_adam, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c9f85",
   "metadata": {},
   "source": [
    "Scenario: Smart Factory Temperature Monitoring\n",
    "A factory monitors the daily average temperature (Â°C) of a critical machine.\n",
    "The goal is to predict tomorrowâ€™s temperature using the last 5 days of temperature readings in order to:\n",
    "Detect overheating trends\n",
    "Schedule preventive maintenance\n",
    "Avoid machine failure\n",
    "ðŸ”¹ Sample Dataset (Time-Series)\n",
    " \n",
    "Day\tTemperature (Â°C)\n",
    "Day 1\t68\n",
    "Day 2\t70\n",
    "Day 3\t71\n",
    "Day 4\t73\n",
    "Day 5\t74\n",
    "Day 6\t76\n",
    "Day 7\t78\n",
    "Day 8\t80\n",
    "Day 9\t82\n",
    "Day 10\t85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a46e670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 6\n",
      "Final train loss (SGD): 3.397282455352979e-14\n",
      "Final val   loss (SGD): 2.3512301445007324\n",
      "Final train loss (Adam): 8.315570454442422e-13\n",
      "Final val   loss (Adam): 2.347770929336548\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C76A9096C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C76A90A440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Last 5 days (Â°C): [84. 90. 23. 84. 89.]\n",
      "Predicted next temp (SGD) : 104.05 Â°C\n",
      "Predicted next temp (Adam): 84.54 Â°C\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "temps = np.array([33,51,63,55,67,88,84,90,23,84,89], dtype=np.float32)\n",
    "\n",
    "\n",
    "window_size = 5\n",
    "X_list, y_list = [], []\n",
    "for i in range(len(temps) - window_size):\n",
    "    X_list.append(temps[i:i+window_size])     \n",
    "    y_list.append(temps[i+window_size])      \n",
    "\n",
    "X = np.array(X_list, dtype=np.float32)      \n",
    "y = np.array(y_list,  dtype=np.float32)       \n",
    "\n",
    "X = X[..., np.newaxis]  \n",
    "y = y[..., np.newaxis]  \n",
    "\n",
    "print(\"Number of samples:\", X.shape[0]) \n",
    "\n",
    "\n",
    "train_size = max(1, int(0.8 * len(X)))  \n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "\n",
    "x_mean, x_std = X_train.mean(), X_train.std() + 1e-8\n",
    "y_mean, y_std = y_train.mean(), y_train.std() + 1e-8\n",
    "\n",
    "X_train_n = (X_train - x_mean) / x_std\n",
    "X_val_n   = (X_val   - x_mean) / x_std\n",
    "y_train_n = (y_train - y_mean) / y_std\n",
    "y_val_n   = (y_val   - y_mean) / y_std\n",
    "\n",
    "\n",
    "def build_model(units=16):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units, activation='tanh', input_shape=(window_size, 1)),\n",
    "        Dense(1) \n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "sgd_opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.5, clipnorm=1.0)\n",
    "\n",
    "model_sgd = build_model(16)\n",
    "model_sgd.compile(optimizer=sgd_opt, loss='mse', metrics=['mae'])\n",
    "\n",
    "history_sgd = model_sgd.fit(\n",
    "    X_train_n, y_train_n,\n",
    "    epochs=250,          \n",
    "    batch_size=5,\n",
    "    validation_data=(X_val_n, y_val_n),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Final train loss (SGD):\", history_sgd.history['loss'][-1])\n",
    "print(\"Final val   loss (SGD):\", history_sgd.history['val_loss'][-1])\n",
    "\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm=1.0)\n",
    "\n",
    "model_adam = build_model(16)\n",
    "model_adam.compile(optimizer=adam_opt, loss='mse', metrics=['mae'])\n",
    "\n",
    "history_adam = model_adam.fit(\n",
    "    X_train_n, y_train_n,\n",
    "    epochs=250,\n",
    "    batch_size=5,\n",
    "    validation_data=(X_val_n, y_val_n),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Final train loss (Adam):\", history_adam.history['loss'][-1])\n",
    "print(\"Final val   loss (Adam):\", history_adam.history['val_loss'][-1])\n",
    "\n",
    "\n",
    "last_5_days = temps[-window_size:]  \n",
    "inp = last_5_days.reshape(1, window_size, 1)\n",
    "\n",
    "\n",
    "inp_n = (inp - x_mean) / x_std\n",
    "\n",
    "pred_n_sgd  = model_sgd.predict(inp_n,  verbose=0)[0, 0]\n",
    "pred_n_adam = model_adam.predict(inp_n, verbose=0)[0, 0]\n",
    "\n",
    "\n",
    "pred_sgd  = pred_n_sgd  * y_std + y_mean\n",
    "pred_adam = pred_n_adam * y_std + y_mean\n",
    "\n",
    "print(\"\\nLast 5 days (Â°C):\", np.round(last_5_days, 2))\n",
    "print(f\"Predicted next temp (SGD) : {pred_sgd:.2f} Â°C\")\n",
    "print(f\"Predicted next temp (Adam): {pred_adam:.2f} Â°C\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5578164d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
