{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7671ccb",
   "metadata": {},
   "source": [
    "HOSPITAL PATIENT DETERIORATION PREDICTION\n",
    "Scenario: ICU Patient Health Risk Forecasting\n",
    "A hospital ICU continuously monitors critical patient vitals.\n",
    "The goal is to predict the patientâ€™s risk score for the next 6 hours using the previous 12 hours of multivariate time-series data, so doctors can intervene before a medical emergency occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2482824",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbf02f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2d02b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hour  HR   BP  O2  Resp  Temp  risk_score\n",
      "0     1  82  120  98    16  36.8    0.000000\n",
      "1     2  85  118  97    17  36.9    6.504384\n",
      "2     3  88  115  96    18  37.0   13.580608\n",
      "3     4  92  112  95    19  37.1   21.454831\n",
      "4     5  96  108  94    20  37.2   29.900894\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "lookback = 12\n",
    "horizon = 6\n",
    "\n",
    "df = pd.read_csv('vitals_dataset_48h_with_risk.csv')\n",
    "features = [\"HR\", \"BP\", \"O2\", \"Resp\", \"Temp\"]\n",
    "target = 'risk_score'\n",
    "print(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "689f4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window(df,features,target,lookback=12,horizon=6):\n",
    "    Xv= df[features].values\n",
    "    yv= df[target].values\n",
    "\n",
    "    x_list,y_list = [],[]\n",
    "\n",
    "    for i in range(len(df) - lookback - horizon +1):\n",
    "        x_list.append(Xv[i:i+lookback])\n",
    "        y_list.append(yv[i+lookback:i+lookback+horizon])\n",
    "    return np.array(x_list),np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e68c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_window(df,features,target,lookback,horizon)\n",
    "n = len(X)\n",
    "split = int(0.8*n)\n",
    "\n",
    "X_train, X_val = X[:split], X[split:]\n",
    "y_train, y_val = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88ed8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler()\n",
    "N, T, F = X_train.shape\n",
    "\n",
    "X_train_2d = X_train.reshape(-1, F)\n",
    "X_val_2d   = X_val.reshape(-1, F)\n",
    "\n",
    "x_scaler.fit(X_train_2d)\n",
    "X_train = x_scaler.transform(X_train_2d).reshape(N, T, F)\n",
    "X_val   = x_scaler.transform(X_val_2d).reshape(X_val.shape[0], T, F)\n",
    "\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1)).reshape(y_train.shape)\n",
    "y_val_scaled   = y_scaler.transform(y_val.reshape(-1, 1)).reshape(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82706c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, horizon):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(64, activation=\"tanh\", input_shape=input_shape),\n",
    "        Dropout(0.25),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af9a8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_report(optimizer, label=\"\"):\n",
    "    tf.random.set_seed(1)\n",
    "\n",
    "    model = build_model((lookback, F), horizon)\n",
    "\n",
    "    # Huber loss reduces sensitivity to outliers/spikes\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.Huber(delta=1.0),\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train_scaled,\n",
    "        validation_data=(X_val, y_val_scaled),\n",
    "        epochs=200,\n",
    "        batch_size=8,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    best_epoch = int(np.argmin(history.history[\"val_loss\"]))\n",
    "    best_train_loss = float(history.history[\"loss\"][best_epoch])\n",
    "    best_val_loss   = float(history.history[\"val_loss\"][best_epoch])\n",
    "\n",
    "    if label == \"\":\n",
    "        print(f\"\\nFinal train loss: {best_train_loss}\")\n",
    "        print(f\"Final val loss  : {best_val_loss}\")\n",
    "    else:\n",
    "        print(f\"\\nFinal train loss ({label}): {best_train_loss}\")\n",
    "        print(f\"Final val loss  ({label}): {best_val_loss}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36475b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Training\\.venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final train loss (SGD): 0.0582413524389267\n",
      "Final val loss  (SGD): 0.008881419897079468\n",
      "\n",
      "Final train loss (Adam): 0.38756808638572693\n",
      "Final val loss  (Adam): 0.012296125292778015\n",
      "\n",
      "Last 12 hours risk_score: [25.91 27.54 28.48 29.38 30.77 31.89 32.59 30.1  29.2  26.2  25.97 26.41]\n",
      "Predicted risk next 6 hours (SGD) :  [30.44 31.99 27.89 30.76 31.32 26.78]\n",
      "Predicted risk next 6 hours (Adam):  [31.89 28.34 31.48 28.73 31.08 28.15]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sgd  = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, clipnorm=1.0)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.1, clipnorm=1.0)\n",
    "\n",
    "model_sgd  = train_and_report(sgd,  label=\"SGD\")\n",
    "model_adam = train_and_report(adam, label=\"Adam\")\n",
    "\n",
    "last_12_vitals = df[features].tail(lookback).values\n",
    "last_12_scaled = x_scaler.transform(last_12_vitals).reshape(1, lookback, F)\n",
    "\n",
    "pred_sgd_scaled  = model_sgd.predict(last_12_scaled,  verbose=0)[0]  # (6,)\n",
    "pred_adam_scaled = model_adam.predict(last_12_scaled, verbose=0)[0]  # (6,)\n",
    "\n",
    "# invert scaling to original risk_score scale\n",
    "pred_sgd  = y_scaler.inverse_transform(pred_sgd_scaled.reshape(-1, 1)).reshape(-1)\n",
    "pred_adam = y_scaler.inverse_transform(pred_adam_scaled.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "last_12_risk = df[target].tail(lookback).values\n",
    "\n",
    "print(\"\\nLast 12 hours risk_score:\", np.round(last_12_risk, 2))\n",
    "print(\"Predicted risk next 6 hours (SGD) : \", np.round(pred_sgd, 2))\n",
    "print(\"Predicted risk next 6 hours (Adam): \", np.round(pred_adam, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee99d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
