{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bdb4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2a315ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 104/104 [00:00<00:00, 387.32it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39774c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998805522918701}]\n"
     ]
    }
   ],
   "source": [
    "text = \"I absolutely love this movie! Great acting.\"\n",
    "result = classifier(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4869f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9993396401405334}]\n"
     ]
    }
   ],
   "source": [
    "text = \"Lovely cant you just do simple thing!!!\"\n",
    "result = classifier(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26de26",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26f297cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 373.75it/s, Materializing param=classifier.weight]                                      \n",
      "BertForTokenClassification LOAD REPORT from: dslim/bert-base-NER\n",
      "Key                      | Status     |  | \n",
      "-------------------------+------------+--+-\n",
      "bert.pooler.dense.bias   | UNEXPECTED |  | \n",
      "bert.pooler.dense.weight | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\n",
    "    task=\"ner\",\n",
    "    model=\"dslim/bert-base-NER\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "361a0d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple → ORG (confidence: 1.00)\n",
      "Tim Cook → PER (confidence: 1.00)\n",
      "Cupertino → LOC (confidence: 0.97)\n"
     ]
    }
   ],
   "source": [
    "text = \"Apple CEO Tim Cook announced new products at Cupertino.\"\n",
    "entities = ner(text)\n",
    "for entity in entities:\n",
    "    print(\n",
    "        f\"{entity['word']} → {entity['entity_group']} \"\n",
    "        f\"(confidence: {entity['score']:.2f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5578da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple → ORG (confidence: 1.00)\n",
      "Tim Cook → PER (confidence: 1.00)\n",
      "Cupertino → LOC (confidence: 0.97)\n"
     ]
    }
   ],
   "source": [
    "text = \"Apple CEO Tim Cook announced new products at Cupertino.\"\n",
    "entities = ner(text)\n",
    "for entity in entities:\n",
    "    print(\n",
    "        f\"{entity['word']} → {entity['entity_group']} \"\n",
    "        f\"(confidence: {entity['score']:.2f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da0dc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G → PER (confidence: 0.60)\n",
      "##anesh Bhel → ORG (confidence: 0.52)\n",
      "Raj → PER (confidence: 0.63)\n",
      "##u → PER (confidence: 0.78)\n"
     ]
    }
   ],
   "source": [
    "text = \"Ganesh Bhel owner is Raju has famous food.\"\n",
    "entities = ner(text)\n",
    "for entity in entities:\n",
    "    print(\n",
    "        f\"{entity['word']} → {entity['entity_group']} \"\n",
    "        f\"(confidence: {entity['score']:.2f})\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529936b",
   "metadata": {},
   "source": [
    "## text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ab3d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8d48492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 201/201 [00:00<00:00, 372.01it/s, Materializing param=model.norm.weight]                              \n",
      "Passing `generation_config` together with generation-related arguments=({'do_sample', 'top_p', 'max_new_tokens', 'temperature'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    max_new_tokens = 150,\n",
    "    temperature = 0.75,\n",
    "    do_sample=True,      # Required to use top_p\n",
    "    top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13dc77c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=150) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "result = generator(\"Explain deep learning in 2 lines:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93a58094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain deep learning in 2 lines:\n",
      "\n",
      "1. Convolutional Neural Networks (CNNs) are a family of deep learning algorithms that use convolutional layers to extract features from images.\n",
      "\n",
      "2. Recurrent Neural Networks (RNNs) are another family of deep learning algorithms that use recurrent layers to generate sequences or patterns.\n",
      "\n",
      "3. Deep Learning can be understood as a set of techniques that can be applied to neural networks to improve their performance in a variety of applications.\n",
      "\n",
      "4. Deep Learning is a broad field that covers a wide range of techniques, including:\n",
      "\n",
      "1. Convolutional Neural Networks (CNNs)\n",
      "2. Recurrent Neural Networks (RNNs)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "output_text = result[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "# Print the generated text\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d64963",
   "metadata": {},
   "source": [
    "## question answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7f8a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 403.24it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "RobertaForQuestionAnswering LOAD REPORT from: deepset/roberta-base-squad2\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "qa = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"deepset/roberta-base-squad2\"\n",
    "    #doc_stride when the model has huge context then it adds the overlapping of the text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94d01f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2024\n"
     ]
    }
   ],
   "source": [
    "context = (\n",
    "    \"Fanatic won Masters and regional championship in year 2024\"\n",
    "    \"They won against loud with 3-11 comeback which was the greatest comeback of all time in history\"\n",
    ")\n",
    "\n",
    "question = \"When did fanatic won championship?\"\n",
    "\n",
    "answer = qa(\n",
    "    question=question,\n",
    "    context=context\n",
    ")\n",
    "print(f\"Answer: {answer['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01570fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 3-11 comeback\n"
     ]
    }
   ],
   "source": [
    "question = \"how did fanatic won against loud?\"\n",
    "\n",
    "answer = qa(\n",
    "    question=question,\n",
    "    context=context\n",
    ")\n",
    "print(f\"Answer: {answer['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235054e",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d45a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Training\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification,Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29178692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 11 examples [00:00, 199.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files=\"Complaints.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6b4972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7e9110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11/11 [00:00<00:00, 259.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.map(\n",
    "    lambda x:tokenizer(\n",
    "        x[\"text\"],\n",
    "        padding = 'max_length',\n",
    "        truncation = True\n",
    "    ),\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bc3ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 332.24it/s, Materializing param=bert.pooler.dense.weight]                               \n",
      "BertForSequenceClassification LOAD REPORT from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa37c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    train_dataset=train_dataset[\"train\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d49c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model.config.id2label = {\n",
    "    0: \"NEGATIVE\",\n",
    "    1: \"NEUTRAL\",\n",
    "    2: \"POSITIVE\"\n",
    "}\n",
    "\n",
    "model.config.label2id = {\n",
    "    \"NEGATIVE\": 0,\n",
    "    \"NEUTRAL\": 1,\n",
    "    \"POSITIVE\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffbfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b1058ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ MODEL TEST RESULTS ================\n",
      "\n",
      "Input Text: 'The service was extremely bad and disappointing.'\n",
      "  NEGATIVE → 0.496\n",
      "   NEUTRAL → 0.282\n",
      "  POSITIVE → 0.222\n",
      "  ▶ Final Prediction: NEGATIVE (0.50)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'The experience was okay, nothing special.'\n",
      "  NEGATIVE → 0.401\n",
      "   NEUTRAL → 0.302\n",
      "  POSITIVE → 0.297\n",
      "  ▶ Final Prediction: NEGATIVE (0.40)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'Absolutely loved the customer support!'\n",
      "  NEGATIVE → 0.351\n",
      "   NEUTRAL → 0.330\n",
      "  POSITIVE → 0.319\n",
      "  ▶ Final Prediction: NEGATIVE (0.35)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'Not bad, but could be better.'\n",
      "  NEGATIVE → 0.447\n",
      "   NEUTRAL → 0.290\n",
      "  POSITIVE → 0.263\n",
      "  ▶ Final Prediction: NEGATIVE (0.45)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'Worst experience ever.'\n",
      "  NEGATIVE → 0.542\n",
      "   NEUTRAL → 0.265\n",
      "  POSITIVE → 0.193\n",
      "  ▶ Final Prediction: NEGATIVE (0.54)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'I am happy with the service.'\n",
      "  NEGATIVE → 0.426\n",
      "   NEUTRAL → 0.304\n",
      "  POSITIVE → 0.270\n",
      "  ▶ Final Prediction: NEGATIVE (0.43)\n",
      "-------------------------------------------------------\n",
      "Input Text: ''\n",
      "  NEGATIVE → 0.504\n",
      "  POSITIVE → 0.254\n",
      "   NEUTRAL → 0.241\n",
      "  ▶ Final Prediction: NEGATIVE (0.50)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'ok'\n",
      "  NEGATIVE → 0.430\n",
      "   NEUTRAL → 0.298\n",
      "  POSITIVE → 0.272\n",
      "  ▶ Final Prediction: NEGATIVE (0.43)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'asdfghjkl'\n",
      "  NEGATIVE → 0.479\n",
      "   NEUTRAL → 0.276\n",
      "  POSITIVE → 0.246\n",
      "  ▶ Final Prediction: NEGATIVE (0.48)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'The product was not bad'\n",
      "  NEGATIVE → 0.403\n",
      "  POSITIVE → 0.303\n",
      "   NEUTRAL → 0.294\n",
      "  ▶ Final Prediction: NEGATIVE (0.40)\n",
      "-------------------------------------------------------\n",
      "Input Text: 'I don't hate the service'\n",
      "  POSITIVE → 0.344\n",
      "  NEGATIVE → 0.341\n",
      "   NEUTRAL → 0.315\n",
      "  ▶ Final Prediction: POSITIVE (0.34)\n",
      "-------------------------------------------------------\n",
      "\n",
      "✅ Model testing completed successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 3: TEST DATA (REAL-WORLD + EDGE CASES)\n",
    "# ------------------------------------------------------------\n",
    "test_sentences = [\n",
    "    \"The service was extremely bad and disappointing.\",\n",
    "    \"The experience was okay, nothing special.\",\n",
    "    \"Absolutely loved the customer support!\",\n",
    "    \"Not bad, but could be better.\",\n",
    "    \"Worst experience ever.\",\n",
    "    \"I am happy with the service.\",\n",
    "    \"\",                         # empty input\n",
    "    \"ok\",                       # very short input\n",
    "    \"asdfghjkl\",                # meaningless input\n",
    "    \"The product was not bad\",  # negation\n",
    "    \"I don't hate the service\"  # double negation\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 4: RUN PREDICTIONS AND DISPLAY RESULTS\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n================ MODEL TEST RESULTS ================\\n\")\n",
    "\n",
    "for text in test_sentences:\n",
    "    # ✅ CHANGED (kept): Normalize pipeline outputs to a list-of-dicts to avoid TypeError\n",
    "    outputs = classifier(text, top_k=None)\n",
    "    if isinstance(outputs, dict):\n",
    "        results = [outputs]                 # single dict\n",
    "    elif outputs and isinstance(outputs[0], list):\n",
    "        results = outputs[0]                # [[{label, score}, ...]] → take first\n",
    "    elif outputs and isinstance(outputs[0], dict):\n",
    "        results = outputs                   # [{label, score}]\n",
    "    else:\n",
    "        results = []                        # fallback empty\n",
    "\n",
    "    # Select label with highest confidence\n",
    "    best_prediction = max(results, key=lambda x: x[\"score\"]) if results else {\"label\": \"N/A\", \"score\": 0.0}\n",
    "\n",
    "    print(f\"Input Text: '{text}'\")\n",
    "    for r in results:\n",
    "        # ✅ CHANGED: replace HTML-escaped '&gt;' with the correct '>' alignment\n",
    "        print(f\"  {r['label']:>8} → {r['score']:.3f}\")\n",
    "\n",
    "    print(f\"  ▶ Final Prediction: {best_prediction['label']} \"\n",
    "          f\"({best_prediction['score']:.2f})\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "\n",
    "print(\"\\n✅ Model testing completed successfully.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c576f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
